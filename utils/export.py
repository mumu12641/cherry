# /**
#  * @file export.py
#  * @brief Utility to extract individual tensor weights from llama2.c binary model files.
#  *
#  * Target Data Source:
#  *   $ wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories110M.bin
#  *    python export.py stories110M.bin stories110M
#  */

import sys
import struct
import os
import numpy as np

def create_directory_if_not_exists(dir_path):
    if not os.path.exists(dir_path):
        try:
            os.makedirs(dir_path, mode=0o755)
            print(f"ğŸ“‚ Creating output directory: {dir_path}")
        except OSError as _:
            print(f"âŒ Failed to create directory: {dir_path}")
            sys.exit(1)
    else:
        print(f"ğŸ“‚ Using existing directory: {dir_path}")

def save_tensor(output_dir, name, data):
    """
    ä¿å­˜ Tensor ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶ï¼Œæ ¼å¼ä¸ C ä»£ç ä¸€è‡´ï¼š
    [ndim (int), shape (int...), data (float...)]
    """
    filepath = os.path.join(output_dir, f"{name}.bin")
    
    shape = data.shape
    ndim = len(shape)
    
    with open(filepath, 'wb') as f:
        # 1. å†™å…¥ ndim
        f.write(struct.pack('i', ndim))
        # 2. å†™å…¥ shape
        f.write(struct.pack(f'{ndim}i', *shape))
        # 3. å†™å…¥æ•°æ® (ç¡®ä¿æ˜¯ float32)
        data.astype(np.float32).tofile(f)

    # æ‰“å°æ—¥å¿—
    shape_str = ", ".join(map(str, shape))
    print(f"ğŸ’¾ Saved: {name:<25} Shape: [{shape_str}]")

def main():
    if len(sys.argv) < 2:
        print(f"Usage: python {sys.argv[0]} <model_file> [output_dir]")
        sys.exit(1)

    model_path = sys.argv[1]
    output_dir = sys.argv[2] if len(sys.argv) >= 3 else "weights"

    print(f"ğŸ“– Reading Model: {model_path}")

    if not os.path.isfile(model_path):
        print(f"âŒ Cannot open model file: {model_path}")
        sys.exit(1)

    # è¯»å– Config (7ä¸ª int)
    # C struct: dim, hidden_dim, n_layers, n_heads, n_kv_heads, vocab_size, seq_len
    with open(model_path, 'rb') as f:
        config_bytes = f.read(28) # 7 * 4 bytes
        if len(config_bytes) != 28:
            print("âŒ Failed to read Config.")
            sys.exit(1)
        
        config = struct.unpack('iiiiiii', config_bytes)
        dim, hidden_dim, n_layers, n_heads, n_kv_heads, vocab_size, seq_len = config

        # å¤„ç† Shared Weights æ ‡å¿—
        shared_weights = vocab_size > 0
        vocab_size = abs(vocab_size)

        print("âš™ï¸  Model Configuration:")
        print(f"   â€¢ dim:        {dim}")
        print(f"   â€¢ hidden_dim: {hidden_dim}")
        print(f"   â€¢ n_layers:   {n_layers}")
        print(f"   â€¢ n_heads:    {n_heads}")
        print(f"   â€¢ n_kv_heads: {n_kv_heads}")
        print(f"   â€¢ vocab_size: {vocab_size} {'(Shared)' if shared_weights else '(Unshared)'}")
        print(f"   â€¢ seq_len:    {seq_len}")
        print("----------------------------------------")

        # è¯»å–å‰©ä½™çš„æ‰€æœ‰æƒé‡æ•°æ®
        print("ğŸš€ Loading weights into memory...")
        # ä»å½“å‰ä½ç½®è¯»å–å‰©ä½™æ‰€æœ‰æ•°æ®ä½œä¸º float32 æ•°ç»„
        weights_data = np.fromfile(f, dtype=np.float32)

    if weights_data.size == 0:
        print("âŒ File contains no weight data.")
        sys.exit(1)

    create_directory_if_not_exists(output_dir)
    print("ğŸš€ Starting extraction...")

    # æŒ‡é’ˆåç§»é‡
    offset = 0
    head_size = dim // n_heads

    # å®šä¹‰éœ€è¦è½¬ç½®çš„æƒé‡åç§°é›†åˆ
    transpose_targets = {
        "layers_wq", "layers_wk", "layers_wv", "layers_wo",
        "layers_w1", "layers_w2", "layers_w3", "output_wcls"
    }

    # è¾…åŠ©å‡½æ•°ï¼šæå–å¹¶å¤„ç†æƒé‡
    token_embeddings_ref = None # ç”¨äº shared weights

    def extract_and_save(name, shape):
        nonlocal offset, token_embeddings_ref
        
        # è®¡ç®—å…ƒç´ æ€»æ•°
        size = np.prod(shape)
        
        # åˆ‡ç‰‡
        data = weights_data[offset : offset + size]
        offset += size
        
        # Reshape
        data = data.reshape(shape)

        # ä¿å­˜ token_embeddings çš„å¼•ç”¨ï¼Œä»¥é˜² output_wcls éœ€è¦å…±äº«
        if name == "token_embeddings":
            token_embeddings_ref = data

        # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬ç½® (æœ€åä¸¤ä¸ªç»´åº¦)
        if name in transpose_targets:
            # äº¤æ¢æœ€åä¸¤ä¸ªç»´åº¦ (-1 å’Œ -2)
            data = np.swapaxes(data, -1, -2)
            # æ³¨æ„ï¼šè½¬ç½®åä¸ºäº†ä¿è¯å†…å­˜è¿ç»­æ€§ä»¥ä¾¿æ­£ç¡®å†™å…¥æ–‡ä»¶ï¼Œé€šå¸¸éœ€è¦ contiguous()
            # ä½† numpy çš„ tofile ä¼šè‡ªåŠ¨å¤„ç†ï¼Œæˆ–è€…æˆ‘ä»¬å¯ä»¥æ˜¾å¼è°ƒç”¨
            data = np.ascontiguousarray(data)

        save_tensor(output_dir, name, data)

    # --- æŒ‰é¡ºåºæå–æƒé‡ ---

    # 1. token_embeddings
    extract_and_save("token_embeddings", (vocab_size, dim))

    # 2. layers_rms_att_weight
    extract_and_save("layers_rms_att_weight", (n_layers, dim))

    # 3. layers_wq
    extract_and_save("layers_wq", (n_layers, dim, n_heads * head_size))

    # 4. layers_wk
    extract_and_save("layers_wk", (n_layers, dim, n_kv_heads * head_size))

    # 5. layers_wv
    extract_and_save("layers_wv", (n_layers, dim, n_kv_heads * head_size))

    # 6. layers_wo
    extract_and_save("layers_wo", (n_layers, n_heads * head_size, dim))

    # 7. layers_rms_ffn_weight
    extract_and_save("layers_rms_ffn_weight", (n_layers, dim))

    # 8. layers_w1
    extract_and_save("layers_w1", (n_layers, hidden_dim, dim))

    # 9. layers_w2
    extract_and_save("layers_w2", (n_layers, dim, hidden_dim))

    # 10. layers_w3
    extract_and_save("layers_w3", (n_layers, hidden_dim, dim))

    # 11. final_rms_norm
    extract_and_save("final_rms_norm", (dim,))

    # 12. output_wcls
    if shared_weights:
        print("â„¹ï¸  Shared Weights detected: Copying token_embeddings to output_wcls...")
        # å¤åˆ¶ token_embeddings
        data = token_embeddings_ref.copy()
        
        # å³ä½¿æ˜¯å…±äº«çš„ï¼ŒæŒ‰ç…§ä½ çš„è¦æ±‚ï¼Œoutput_wcls ä¹Ÿéœ€è¦è½¬ç½®
        # token_embeddings æ˜¯ [vocab, dim]ï¼Œè½¬ç½®åå˜æˆ [dim, vocab]
        if "output_wcls" in transpose_targets:
            data = np.swapaxes(data, -1, -2)
            data = np.ascontiguousarray(data)
            
        save_tensor(output_dir, "output_wcls", data)
    else:
        extract_and_save("output_wcls", (vocab_size, dim))

    print(f"\nâœ¨ Done! All weights have been extracted to '{output_dir}'.")

if __name__ == "__main__":
    main()